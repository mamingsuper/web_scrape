{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is API\n",
    "- ü§° API stands for Application Programming Interface, which is a software intermediary that allows two applications to talk to each other. Each time you use an app like Facebook, send an instant message, or check the weather on your phone, you‚Äôre using an API. API is also used for data collection, data analysis, and data visualization. We can request data from a website's API and then use the data for our own purpose.\n",
    "\n",
    "- ü§† Some APIs are free, but definitely not include Twitter/X under the leadership of Ellon Musk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['kind', 'totalItems', 'items'])\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "# request data from API offered by Google\n",
    "r = requests.get(\"https://www.googleapis.com//books/v1/volumes?q=python\")\n",
    "data = r.json()\n",
    "print(data.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/f1n8t0d976g6wkh90qcr60vm00ccf3/T/ipykernel_11123/3220023745.py:2: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead.\n",
      "  formatdata = json_normalize(data['items'])\n"
     ]
    }
   ],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "formatdata = json_normalize(data['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['kind', 'id', 'etag', 'selfLink', 'volumeInfo.title',\n",
       "       'volumeInfo.subtitle', 'volumeInfo.authors', 'volumeInfo.publisher',\n",
       "       'volumeInfo.publishedDate', 'volumeInfo.description',\n",
       "       'volumeInfo.industryIdentifiers', 'volumeInfo.readingModes.text',\n",
       "       'volumeInfo.readingModes.image', 'volumeInfo.pageCount',\n",
       "       'volumeInfo.printType', 'volumeInfo.categories',\n",
       "       'volumeInfo.averageRating', 'volumeInfo.ratingsCount',\n",
       "       'volumeInfo.maturityRating', 'volumeInfo.allowAnonLogging',\n",
       "       'volumeInfo.contentVersion',\n",
       "       'volumeInfo.panelizationSummary.containsEpubBubbles',\n",
       "       'volumeInfo.panelizationSummary.containsImageBubbles',\n",
       "       'volumeInfo.imageLinks.smallThumbnail',\n",
       "       'volumeInfo.imageLinks.thumbnail', 'volumeInfo.language',\n",
       "       'volumeInfo.previewLink', 'volumeInfo.infoLink',\n",
       "       'volumeInfo.canonicalVolumeLink', 'saleInfo.country',\n",
       "       'saleInfo.saleability', 'saleInfo.isEbook', 'accessInfo.country',\n",
       "       'accessInfo.viewability', 'accessInfo.embeddable',\n",
       "       'accessInfo.publicDomain', 'accessInfo.textToSpeechPermission',\n",
       "       'accessInfo.epub.isAvailable', 'accessInfo.pdf.isAvailable',\n",
       "       'accessInfo.webReaderLink', 'accessInfo.accessViewStatus',\n",
       "       'accessInfo.quoteSharingAllowed', 'searchInfo.textSnippet',\n",
       "       'saleInfo.listPrice.amount', 'saleInfo.listPrice.currencyCode',\n",
       "       'saleInfo.retailPrice.amount', 'saleInfo.retailPrice.currencyCode',\n",
       "       'saleInfo.buyLink', 'saleInfo.offers', 'accessInfo.pdf.acsTokenLink',\n",
       "       'accessInfo.epub.acsTokenLink'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatdata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 509,no more data.\n"
     ]
    }
   ],
   "source": [
    "# request more data from API offered by Google\n",
    "all_data = []\n",
    "i = 0\n",
    "while True:\n",
    "    r = requests.get(\"https://www.googleapis.com/\"\n",
    "        \"books/v1/volumes?q=python&maxResults=\"\n",
    "        f\"40&startIndex={i}\"\n",
    "        )\n",
    "    data = r.json()\n",
    "    if not \"items\" in data:\n",
    "        print(f\"Retrieved {len(all_data)},\" \"no more data.\")\n",
    "        break\n",
    "    all_data.extend(data[\"items\"])\n",
    "    i += 40 # increase the index by 40 for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/f1n8t0d976g6wkh90qcr60vm00ccf3/T/ipykernel_11123/1523326818.py:1: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead.\n",
      "  d = json_normalize(all_data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>id</th>\n",
       "      <th>etag</th>\n",
       "      <th>selfLink</th>\n",
       "      <th>volumeInfo.title</th>\n",
       "      <th>volumeInfo.subtitle</th>\n",
       "      <th>volumeInfo.authors</th>\n",
       "      <th>volumeInfo.publisher</th>\n",
       "      <th>volumeInfo.publishedDate</th>\n",
       "      <th>volumeInfo.description</th>\n",
       "      <th>...</th>\n",
       "      <th>saleInfo.listPrice.amount</th>\n",
       "      <th>saleInfo.listPrice.currencyCode</th>\n",
       "      <th>saleInfo.retailPrice.amount</th>\n",
       "      <th>saleInfo.retailPrice.currencyCode</th>\n",
       "      <th>saleInfo.buyLink</th>\n",
       "      <th>saleInfo.offers</th>\n",
       "      <th>accessInfo.pdf.acsTokenLink</th>\n",
       "      <th>accessInfo.epub.acsTokenLink</th>\n",
       "      <th>accessInfo.epub.downloadLink</th>\n",
       "      <th>accessInfo.pdf.downloadLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>books#volume</td>\n",
       "      <td>ZPnvHMmcrEoC</td>\n",
       "      <td>5S2pj8QJepw</td>\n",
       "      <td>https://www.googleapis.com/books/v1/volumes/ZP...</td>\n",
       "      <td>Einf√ºhrung in Python</td>\n",
       "      <td></td>\n",
       "      <td>[Mark Lutz, David Ascher]</td>\n",
       "      <td>O'Reilly Germany</td>\n",
       "      <td>2007</td>\n",
       "      <td>Google tut es, YouTube tut es, Zope und die NA...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>books#volume</td>\n",
       "      <td>7q72DwAAQBAJ</td>\n",
       "      <td>m5qlKrufuWc</td>\n",
       "      <td>https://www.googleapis.com/books/v1/volumes/7q...</td>\n",
       "      <td>Python-Tricks</td>\n",
       "      <td>Praktische Tipps f√ºr Fortgeschrittene</td>\n",
       "      <td>[Dan Bader]</td>\n",
       "      <td>dpunkt.verlag</td>\n",
       "      <td>2018-08-23</td>\n",
       "      <td>Dieses Buch soll aus dir einen besseren Python...</td>\n",
       "      <td>...</td>\n",
       "      <td>29.90</td>\n",
       "      <td>EUR</td>\n",
       "      <td>29.90</td>\n",
       "      <td>EUR</td>\n",
       "      <td>https://play.google.com/store/books/details?id...</td>\n",
       "      <td>[{'finskyOfferType': 1, 'listPrice': {'amountI...</td>\n",
       "      <td>http://books.google.de/books/download/Python_T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>books#volume</td>\n",
       "      <td>9aFwIoQ9dBUC</td>\n",
       "      <td>djeJKup/s+s</td>\n",
       "      <td>https://www.googleapis.com/books/v1/volumes/9a...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Grundlagen und Praxis</td>\n",
       "      <td>[Peter Walerowski]</td>\n",
       "      <td>Pearson Deutschland GmbH</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://books.google.de/books/download/Python-s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>books#volume</td>\n",
       "      <td>UK72DwAAQBAJ</td>\n",
       "      <td>Zidoaok0Gcc</td>\n",
       "      <td>https://www.googleapis.com/books/v1/volumes/UK...</td>\n",
       "      <td>Einf√ºhrung in Machine Learning mit Python</td>\n",
       "      <td>Praxiswissen Data Science</td>\n",
       "      <td>[Andreas C. M√ºller, Sarah Guido]</td>\n",
       "      <td>O'Reilly</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>Machine Learning ist zu einem wichtigen Bestan...</td>\n",
       "      <td>...</td>\n",
       "      <td>39.90</td>\n",
       "      <td>EUR</td>\n",
       "      <td>39.90</td>\n",
       "      <td>EUR</td>\n",
       "      <td>https://play.google.com/store/books/details?id...</td>\n",
       "      <td>[{'finskyOfferType': 1, 'listPrice': {'amountI...</td>\n",
       "      <td>http://books.google.de/books/download/Einf%C3%...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>books#volume</td>\n",
       "      <td>Va-HxHRndAUC</td>\n",
       "      <td>y+KwZVuYKNU</td>\n",
       "      <td>https://www.googleapis.com/books/v1/volumes/Va...</td>\n",
       "      <td>Python 3 - Intensivkurs</td>\n",
       "      <td>Projekte erfolgreich realisieren</td>\n",
       "      <td>[Mark Pilgrim]</td>\n",
       "      <td>Springer-Verlag</td>\n",
       "      <td>2010-06-16</td>\n",
       "      <td>Python ist eine vollwertige Programmiersprache...</td>\n",
       "      <td>...</td>\n",
       "      <td>42.25</td>\n",
       "      <td>EUR</td>\n",
       "      <td>42.25</td>\n",
       "      <td>EUR</td>\n",
       "      <td>https://play.google.com/store/books/details?id...</td>\n",
       "      <td>[{'finskyOfferType': 1, 'listPrice': {'amountI...</td>\n",
       "      <td>http://books.google.de/books/download/Python_3...</td>\n",
       "      <td>http://books.google.de/books/download/Python_3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           kind            id         etag  \\\n",
       "0  books#volume  ZPnvHMmcrEoC  5S2pj8QJepw   \n",
       "1  books#volume  7q72DwAAQBAJ  m5qlKrufuWc   \n",
       "2  books#volume  9aFwIoQ9dBUC  djeJKup/s+s   \n",
       "3  books#volume  UK72DwAAQBAJ  Zidoaok0Gcc   \n",
       "4  books#volume  Va-HxHRndAUC  y+KwZVuYKNU   \n",
       "\n",
       "                                            selfLink  \\\n",
       "0  https://www.googleapis.com/books/v1/volumes/ZP...   \n",
       "1  https://www.googleapis.com/books/v1/volumes/7q...   \n",
       "2  https://www.googleapis.com/books/v1/volumes/9a...   \n",
       "3  https://www.googleapis.com/books/v1/volumes/UK...   \n",
       "4  https://www.googleapis.com/books/v1/volumes/Va...   \n",
       "\n",
       "                            volumeInfo.title  \\\n",
       "0                       Einf√ºhrung in Python   \n",
       "1                              Python-Tricks   \n",
       "2                                     Python   \n",
       "3  Einf√ºhrung in Machine Learning mit Python   \n",
       "4                    Python 3 - Intensivkurs   \n",
       "\n",
       "                     volumeInfo.subtitle                volumeInfo.authors  \\\n",
       "0                                                [Mark Lutz, David Ascher]   \n",
       "1  Praktische Tipps f√ºr Fortgeschrittene                       [Dan Bader]   \n",
       "2                  Grundlagen und Praxis                [Peter Walerowski]   \n",
       "3              Praxiswissen Data Science  [Andreas C. M√ºller, Sarah Guido]   \n",
       "4       Projekte erfolgreich realisieren                    [Mark Pilgrim]   \n",
       "\n",
       "       volumeInfo.publisher volumeInfo.publishedDate  \\\n",
       "0          O'Reilly Germany                     2007   \n",
       "1             dpunkt.verlag               2018-08-23   \n",
       "2  Pearson Deutschland GmbH                     2008   \n",
       "3                  O'Reilly               2017-07-21   \n",
       "4           Springer-Verlag               2010-06-16   \n",
       "\n",
       "                              volumeInfo.description  ...  \\\n",
       "0  Google tut es, YouTube tut es, Zope und die NA...  ...   \n",
       "1  Dieses Buch soll aus dir einen besseren Python...  ...   \n",
       "2                                                NaN  ...   \n",
       "3  Machine Learning ist zu einem wichtigen Bestan...  ...   \n",
       "4  Python ist eine vollwertige Programmiersprache...  ...   \n",
       "\n",
       "  saleInfo.listPrice.amount  saleInfo.listPrice.currencyCode  \\\n",
       "0                       NaN                              NaN   \n",
       "1                     29.90                              EUR   \n",
       "2                       NaN                              NaN   \n",
       "3                     39.90                              EUR   \n",
       "4                     42.25                              EUR   \n",
       "\n",
       "   saleInfo.retailPrice.amount  saleInfo.retailPrice.currencyCode  \\\n",
       "0                          NaN                                NaN   \n",
       "1                        29.90                                EUR   \n",
       "2                          NaN                                NaN   \n",
       "3                        39.90                                EUR   \n",
       "4                        42.25                                EUR   \n",
       "\n",
       "                                    saleInfo.buyLink  \\\n",
       "0                                                NaN   \n",
       "1  https://play.google.com/store/books/details?id...   \n",
       "2                                                NaN   \n",
       "3  https://play.google.com/store/books/details?id...   \n",
       "4  https://play.google.com/store/books/details?id...   \n",
       "\n",
       "                                     saleInfo.offers  \\\n",
       "0                                                NaN   \n",
       "1  [{'finskyOfferType': 1, 'listPrice': {'amountI...   \n",
       "2                                                NaN   \n",
       "3  [{'finskyOfferType': 1, 'listPrice': {'amountI...   \n",
       "4  [{'finskyOfferType': 1, 'listPrice': {'amountI...   \n",
       "\n",
       "                         accessInfo.pdf.acsTokenLink  \\\n",
       "0                                                NaN   \n",
       "1  http://books.google.de/books/download/Python_T...   \n",
       "2  http://books.google.de/books/download/Python-s...   \n",
       "3  http://books.google.de/books/download/Einf%C3%...   \n",
       "4  http://books.google.de/books/download/Python_3...   \n",
       "\n",
       "                        accessInfo.epub.acsTokenLink  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  http://books.google.de/books/download/Python_3...   \n",
       "\n",
       "  accessInfo.epub.downloadLink  accessInfo.pdf.downloadLink  \n",
       "0                          NaN                          NaN  \n",
       "1                          NaN                          NaN  \n",
       "2                          NaN                          NaN  \n",
       "3                          NaN                          NaN  \n",
       "4                          NaN                          NaN  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = json_normalize(all_data)\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0  VideoWatch: Hostage families storm Israeli par...   \n",
      "1  VideoDramatic videos show Storm Isha damage so...   \n",
      "2                             VideoBBC World Service   \n",
      "3  VideoMother pleads for daughter's return after...   \n",
      "4  VideoIs Storm Isha hanging around? - watch lat...   \n",
      "\n",
      "                                                Link  \\\n",
      "0  https://www.bbc.com/news/world-middle-east-680...   \n",
      "1               https://www.bbc.com/news/uk-68055708   \n",
      "2            https://www.bbc.com/news/world-65432059   \n",
      "3  https://www.bbc.com/news/world-middle-east-671...   \n",
      "4               https://www.bbc.com/news/uk-68054980   \n",
      "\n",
      "                                             Content  \n",
      "0  This video can not be played A group of famili...  \n",
      "1  This video can not be played Videos shared on ...  \n",
      "2  This video can not be played International new...  \n",
      "3  This video can not be played Hamas' armed wing...  \n",
      "4  This video can not be played BBC Weather's Car...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to get the content of the article\n",
    "def get_article_content(article_url):\n",
    "    # Send a GET request to the article\n",
    "    response = requests.get(article_url)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the article page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # Find the content of the article using the class name for paragraphs\n",
    "        article_paragraphs = soup.find_all('p', class_='ssrcss-1q0x1qg-Paragraph')\n",
    "        # Join the text from all the paragraphs to form the content\n",
    "        content = ' '.join(paragraph.get_text() for paragraph in article_paragraphs)\n",
    "        return content\n",
    "    # Return None if the request fails or the content is not found\n",
    "    return None\n",
    "\n",
    "# The URL of the BBC News page\n",
    "url = 'https://www.bbc.com/news'\n",
    "\n",
    "# Sending a GET request to the website\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parsing the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Finding the ordered list that contains the most watched news\n",
    "    most_watched_list = soup.find('ol', class_='gel-layout gel-layout--no-flex')\n",
    "\n",
    "    # List to store the scraped data\n",
    "    data = []\n",
    "\n",
    "    # Check if the list is found\n",
    "    if most_watched_list:\n",
    "        # Extracting the news titles, links, and content\n",
    "        for item in most_watched_list.find_all('li', recursive=False):\n",
    "            a_tag = item.find('a', class_='gs-c-promo-heading')\n",
    "            if a_tag:\n",
    "                title = a_tag.get_text(strip=True)\n",
    "                link = a_tag['href']\n",
    "                full_link = f'https://www.bbc.com{link}' if link.startswith('/') else link\n",
    "                \n",
    "                # Scrape the content of the article\n",
    "                content = get_article_content(full_link)\n",
    "\n",
    "                # Add the data to the list\n",
    "                data.append({\n",
    "                    'Title': title,\n",
    "                    'Link': full_link,\n",
    "                    'Content': content\n",
    "                })\n",
    "\n",
    "    # Create a DataFrame from the scraped data\n",
    "    bbcdata = pd.DataFrame(data)\n",
    "    print(bbcdata)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the webpage, status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0  VideoWatch: Hostage families storm Israeli par...   \n",
      "1  VideoWatch: The crazy flight diversions caused...   \n",
      "2                             VideoBBC World Service   \n",
      "3  VideoDramatic videos show Storm Isha damage so...   \n",
      "4  VideoFreezing US weather causes striking ice f...   \n",
      "\n",
      "                                                Link  \\\n",
      "0  https://www.bbc.com/news/world-middle-east-680...   \n",
      "1               https://www.bbc.com/news/uk-68062244   \n",
      "2            https://www.bbc.com/news/world-65432059   \n",
      "3               https://www.bbc.com/news/uk-68055708   \n",
      "4  https://www.bbc.com/news/world-us-canada-68047456   \n",
      "\n",
      "                                             Content  \n",
      "0  A group of families of Israeli hostages still ...  \n",
      "1  The strong winds caused by Storm Isha brought ...  \n",
      "2  International news, analysis and features from...  \n",
      "3  Videos shared on social media have captured ne...  \n",
      "4  A video captured by a drone shows striking ice...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to get the content of the article using CSS selectors\n",
    "def get_article_content(article_url):\n",
    "    response = requests.get(article_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # Use the provided CSS selector to select the content\n",
    "        content_elements = soup.select('.e5tfeyi1')\n",
    "\n",
    "        # Initialize an empty list to hold all paragraphs\n",
    "        content_paragraphs = []\n",
    "\n",
    "        # Go through all content elements and extract text\n",
    "        for element in content_elements:\n",
    "            paragraph = element.get_text(strip=True)\n",
    "            content_paragraphs.append(paragraph)\n",
    "\n",
    "        # Join all the paragraphs into one string of content\n",
    "        content = ' '.join(content_paragraphs)\n",
    "        return content\n",
    "    return None\n",
    "\n",
    "\n",
    "# The URL of the BBC News page\n",
    "url = 'https://www.bbc.com/news'\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Use CSS selector for the most watched news list (modify if necessary)\n",
    "    most_watched_elements = soup.select('.nw-c-most-watched .gel-layout--no-flex a')\n",
    "\n",
    "    data = []\n",
    "    for link_element in most_watched_elements:\n",
    "        title = link_element.get_text().strip()\n",
    "        link = link_element['href'].strip()\n",
    "        full_link = f'https://www.bbc.com{link}' if link.startswith('/') else link\n",
    "\n",
    "        content = get_article_content(full_link)\n",
    "        data.append({\n",
    "            'Title': title,\n",
    "            'Link': full_link,\n",
    "            'Content': content\n",
    "        })\n",
    "\n",
    "    bbcdatathree = pd.DataFrame(data)\n",
    "    print(bbcdatathree)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the webpage, status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A group of families of Israeli hostages still being held in Gaza have stormed a meeting at the Knesset, Israel\\'s parliament.They broke through security and interrupted a finance meeting - protesting that it was deliberating while their loved ones remain in captivity.One held up a sign reading: \"You will not sit here, while our children are dying there.\"Israel says more than 130 people remain unaccounted for after they were abducted during the 7 October attacks by Hamas.More than 100 captives were released during a six-day ceasefire at the end of November.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbcdatathree['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46923546717421abd53c5469a217126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2c8fd6712c4d628c2cb994e2daeb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589966cefa7d409b897ff4742da60ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb3cdaf829642949b4599c36a6aa836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4109aea948974cd8bbea88aa4565b7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Function to get sentiment\n",
    "def get_sentiment(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    sentiment = np.argmax(scores)\n",
    "    return sentiment  # 0 -> Negati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbcdatathree['Sentiment'] = bbcdatathree['Content'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbcdatathree['Sentiment']\n",
    "# 0 -> Negative, 1 -> Neutral, 2 -> Positive, recode var \"Sentiment\"\n",
    "bbcdatathree['Sentiment'] = bbcdatathree['Sentiment'].replace({0: 'Negative', 1: 'Neutral', 2: 'Positive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VideoWatch: Hostage families storm Israeli par...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VideoWatch: The crazy flight diversions caused...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VideoBBC World Service</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VideoDramatic videos show Storm Isha damage so...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VideoFreezing US weather causes striking ice f...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Sentiment\n",
       "0  VideoWatch: Hostage families storm Israeli par...  Negative\n",
       "1  VideoWatch: The crazy flight diversions caused...  Negative\n",
       "2                             VideoBBC World Service  Positive\n",
       "3  VideoDramatic videos show Storm Isha damage so...  Negative\n",
       "4  VideoFreezing US weather causes striking ice f...  Negative"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbcdatathree[[\"Title\", \"Sentiment\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
