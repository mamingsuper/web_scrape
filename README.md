# Logistics of Scraping Weibo Data Class

### üêµ¬†Preparations

1. Install **Python** on your computer. Here is a tutorial from Datacamp.

-  [https://www.datacamp.com/blog/how-to-install-python](https://www.datacamp.com/blog/how-to-install-python)

2. Register a **Weibo** account (optional).
- We will provide all we need for data collection during the class, but collect massive-scale data in the future requires a Weibo account.
  
3. Install Chrome or Edge Browser. 
- No advertisement, only because I am more familiar with it.
  
4. Read the basic and (very brief ‚ùó) introduction about the fundamental knowledge of website.

- the goal of this class is not to train you as professional developers, but knowing basic html knowledge is helpful for effectively locate and find the data we need. 
[https://www.dannidanliu.com/understanding-html-basics-for-web-scraping/](https://www.dannidanliu.com/understanding-html-basics-for-web-scraping/)
  


### üê∂¬†Some tools

1. **No code method (need üí≤)**
- Octoparse An desktop application allows you to scrape data from multiple sources: social media, e-commerce, government, etc‚Ä¶
[https://www.bazhuayu.com/](https://www.bazhuayu.com/)
- Qingbo Big Data, which will collect the data based on your request and then return the data.
[https://yuqing.gsdata.cn/](https://yuqing.gsdata.cn/)
2. **Low code  (collect data based on open-source packages)
Example: collect discussion about digital governance on Weibo**
[Google Colaboratory](https://colab.research.google.com/drive/1ihQyXTPRplaBYdb7j6e7QBKV9JXX4quz?usp=drive_link)

- WeiboSpider
[https://github.com/nghuyong/WeiboSpider](https://github.com/nghuyong/WeiboSpider)

- weibo-search
[https://github.com/dataabc/weibo-search](https://github.com/dataabc/weibo-search)

1. **High code (write all the code from 0 )
Example: collect data from Russia Today on Weibo**
- Bonus: ```RT_weibo.ipynb```
- Useful tools: [Curltransformer](https://curlconverter.com/)
